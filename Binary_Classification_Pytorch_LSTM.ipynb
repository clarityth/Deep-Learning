{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKelMv2k5gNx",
        "outputId": "3524ccac-f7e9-404a-ab3f-0f05ff022cba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read file \"hw1_data.tsv\"\n",
        "file = open(\"/content/drive/MyDrive/hw1_data.tsv\",'r')\n",
        "ori_data = file.read().strip().split(\"\\n\")\n",
        "data = []\n",
        "for item in ori_data:\n",
        "  item = item.split(\"\\t\")\n",
        "  if len(item[0]) >0:\n",
        "    data.append((item[0],item[1]))\n",
        "print(len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObQrvnbB8hPZ",
        "outputId": "11cb141a-cf67-4fab-b1ce-66d017c860bb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSiVjnSKBlcK",
        "outputId": "b675a730-0bb2-4921-889a-a768f7b85dda"
      },
      "source": [
        "### Training data pre-processing\n",
        "texts, labels = [], []\n",
        "label2idx = {\"0\":0, \"1\":1}\n",
        "for item in data:\n",
        "  text = item[0]\n",
        "\n",
        "  ## Preprocessing (if you want to add, please add more)\n",
        "  ################################################################################\n",
        "  text = text.replace(\"  \",\" \") ## Replace double space\n",
        "  text = text.replace(\",\", \"\") ## Replace comma to \"\"\n",
        "  text = text.lower()  ## Lower cases\n",
        "  ################################################################################\n",
        "\n",
        "  label = label2idx[item[1]]\n",
        "\n",
        "  texts.append(text)\n",
        "  labels.append(label)\n",
        "\n",
        "print(\"*\"*50)\n",
        "print(\"Total number of datasets\")\n",
        "print(len(texts))\n",
        "print(len(labels))\n",
        "print(\"*\"*50)\n",
        "\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************************\n",
            "Total number of datasets\n",
            "300\n",
            "300\n",
            "**************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Split into train/dev/test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "### Write a code for collecting samples for each class\n",
        "################################################################################\n",
        "pos,neg = [], []\n",
        "train_texts, dev_texts, test_texts, train_labels, dev_labels, test_labels = [], [], [], [], [], []\n",
        "for a,b in zip(texts,labels):\n",
        "  if b == '1':\n",
        "    pos.append((a,b))\n",
        "  else:\n",
        "    neg.append((a,b))\n",
        "for a,b in pos[:100]:\n",
        "  test_texts.append(a)\n",
        "  test_labels.append(b)\n",
        "for a,b in neg[:100]:\n",
        "  test_texts.append(a)\n",
        "  test_labels.append(b)\n",
        "\n",
        "for a,b in pos[100:200]:\n",
        "  dev_texts.append(a)\n",
        "  dev_labels.append(b)\n",
        "for a,b in neg[:100]:\n",
        "  dev_texts.append(a)\n",
        "  dev_labels.append(b)\n",
        "\n",
        "for a,b in pos[200:]:\n",
        "  train_texts.append(a)\n",
        "  train_labels.append(b)\n",
        "for a,b in neg[:100]:\n",
        "  train_texts.append(a)\n",
        "  train_labels.append(b)\n",
        "################################################################################\n",
        "\n",
        "print(\"Train Dataset Examples\")\n",
        "print(train_texts[:3])\n",
        "print(train_labels[:3])\n",
        "print(\"*\"*50)\n",
        "print(train_labels)\n",
        "print(dev_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZyzodaGovkH",
        "outputId": "43271edc-f801-4f71-a9ff-610eef343c29"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Dataset Examples\n",
            "['that loves its characters and communicates something rather beautiful about human nature ', 'demonstrates that the director of such hollywood blockbusters as patriot games can still turn out a small  personal film with an emotional wallop . ', 'of saucy ']\n",
            "[1, 1, 1]\n",
            "**************************************************\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4wmL0jRBw2_",
        "outputId": "167d01a2-7193-42cf-a9b4-c29750746c79"
      },
      "source": [
        "## Construct a vocabulary\n",
        "from collections import Counter\n",
        "\n",
        "all_words = []\n",
        "for item in train_texts:\n",
        "  all_words += item.split()\n",
        "for item in dev_texts:\n",
        "  all_words += item.split()\n",
        "\n",
        "## Build a dictionary that maps words to integers\n",
        "counts = Counter(all_words)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {'<pad>':0, \"<unk>\":1}\n",
        "vocab_to_int.update({word: ii for ii, word in enumerate(vocab,2)})\n",
        "print(vocab_to_int)\n",
        "print(len(vocab_to_int))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<pad>': 0, '<unk>': 1, 'and': 2, 'the': 3, 'a': 4, '.': 5, 'of': 6, 'it': 7, \"'s\": 8, 'that': 9, 'to': 10, 'with': 11, 'in': 12, 'as': 13, 'film': 14, 'an': 15, 'is': 16, 'about': 17, 'most': 18, 'his': 19, 'for': 20, 'this': 21, 'funny': 22, 'has': 23, 'one': 24, 'its': 25, 'can': 26, 'are': 27, 'more': 28, 'young': 29, 'face': 30, 'by': 31, 'on': 32, 'very': 33, 'good': 34, 'best': 35, 'have': 36, 'beautiful': 37, 'human': 38, 'out': 39, 'all': 40, 'woman': 41, 'some': 42, 'if': 43, 'world': 44, 'i': 45, 'between': 46, 'feature': 47, \"n't\": 48, 'movie': 49, 'life': 50, 'so': 51, 'family': 52, 'something': 53, 'rather': 54, 'through': 55, 'than': 56, '`': 57, 'original': 58, 'your': 59, 'from': 60, 'performances': 61, '``': 62, \"''\": 63, 'issues': 64, 'what': 65, 'liked': 66, '--': 67, 'silly': 68, 'storyline': 69, 'he': 70, 'us': 71, 'be': 72, 'rich': 73, 'magnificent': 74, 'like': 75, 'much': 76, 'fun': 77, 'story': 78, 'robert': 79, 'terrific': 80, '...': 81, 'movies': 82, 'new': 83, 'enough': 84, 'comedy': 85, 'would': 86, 'takes': 87, 'attractive': 88, 'time': 89, 'how': 90, 'flaws': 91, 'way': 92, 'you': 93, 'at': 94, 'when': 95, 'men': 96, 'sometimes': 97, 'but': 98, 'outrageous': 99, 'loves': 100, 'characters': 101, 'communicates': 102, 'nature': 103, 'demonstrates': 104, 'director': 105, 'such': 106, 'hollywood': 107, 'blockbusters': 108, 'patriot': 109, 'games': 110, 'still': 111, 'turn': 112, 'small': 113, 'personal': 114, 'emotional': 115, 'wallop': 116, 'saucy': 117, 'deeply': 118, 'thought': 119, 'right-thinking': 120, \"'\": 121, 'films': 122, 'greatest': 123, 'musicians': 124, 'usual': 125, 'intelligence': 126, 'subtlety': 127, 'swimming': 128, 'above': 129, 'casting': 130, 'actress': 131, 'whose': 132, 'projects': 133, 'doubts': 134, 'yearnings': 135, 'succeeds': 136, 'equals': 137, 'ways': 138, 'even': 139, 'betters': 140, 'anything': 141, 'see': 142, 'karen': 143, 'black': 144, 'who': 145, 'camps': 146, 'up': 147, 'storm': 148, 'fringe': 149, 'feminist': 150, 'conspiracy': 151, 'theorist': 152, 'named': 153, 'dirty': 154, 'dick': 155, 'smile': 156, 'comes': 157, 'brave': 158, 'uninhibited': 159, 'enriched': 160, 'imaginatively': 161, 'mixed': 162, 'cast': 163, 'antic': 164, 'spirits': 165, 'cinema': 166, 'viewing': 167, 'alternative': 168, 'cylinders': 169, 'another': 170, 'man': 171, 'clone': 172, 'weaving': 173, 'theme': 174, 'throughout': 175, 'adults': 176, 'marriage': 177, 'think': 178, 'real': 179, 'tucked': 180, 'crude': 181, 'heroes': 182, 'sharply': 183, 'covers': 184, 'territory': 185, 'wit': 186, 'originality': 187, 'suggesting': 188, 'fourth': 189, 'gorgeous': 190, 'deceptively': 191, 'minimalist': 192, 'cross': 193, 'swords': 194, 'them': 195, 'proves': 196, 'once': 197, 'again': 198, 'lost': 199, 'touch': 200, 'bringing': 201, 'off': 202, 'superb': 203, 'performance': 204, 'admittedly': 205, 'middling': 206, 'muddle': 207, 'splashed': 208, 'bloody': 209, 'beauty': 210, 'vivid': 211, 'any': 212, 'scorsese': 213, 'ever': 214, 'given': 215, 'beautifully': 216, 'subtle': 217, 'touching': 218, 'son': 219, 'room': 220, 'starts': 221, 'legend': 222, 'veins': 223, 'stuff': 224, 'pretty': 225, 'damned': 226, 'storylines': 227, 'woven': 228, 'together': 229, 'skilfully': 230, 'swooping': 231, 'aerial': 232, 'shots': 233, 'breathtaking': 234, 'overall': 235, 'experience': 236, 'awesome': 237, 'seem': 238, 'fresh': 239, 'pays': 240, 'earnest': 241, 'homage': 242, 'turntablists': 243, 'affirm': 244, 'love': 245, 'power': 246, 'help': 247, 'people': 248, 'endure': 249, 'almost': 250, 'unimaginable': 251, 'horror': 252, 'absolute': 253, 'joy': 254, 'generates': 255, 'without': 256, 'highs': 257, 'lows': 258, 'based': 259, 'true': 260, 'historically': 261, 'significant': 262, 'well-rounded': 263, 'tribute': 264, 'deniro': 265, 'khouri': 266, 'manages': 267, 'flair': 268, 'keep': 269, 'extremes': 270, 'screwball': 271, 'farce': 272, 'blood-curdling': 273, 'intensity': 274, 'continuum': 275, 'fashioning': 276, 'engrossing': 277, 'entertainment': 278, 'spiffy': 279, 'animated': 280, 'alternating': 281, 'facetious': 282, 'comic': 283, 'parody': 284, 'pulp': 285, 'melodrama': 286, 'smart-aleck': 287, 'tosses': 288, 'around': 289, 'intriguing': 290, 'questions': 291, 'difference': 292, 'android': 293, 'generous': 294, 'subversive': 295, 'artworks': 296, 'does': 297, 'follow': 298, 'stale': 299, 'standard': 300, 'connect-the-dots': 301, 'which': 302, 'become': 303, 'commonplace': 304, 'explore': 305, 'seamy': 306, 'underbelly': 307, 'criminal': 308, 'yet': 309, 'duvall': 310, '!': 311, 'sudden': 312, 'wisdom': 313, 'acted': 314, 'directed': 315, 'clear': 316, 'washington': 317, 'certainly': 318, 'career': 319, 'ahead': 320, 'him': 321, 'memory': 322, 'respectable': 323, 'hate': 324, 'tear': 325, 'eyes': 326, 'away': 327, 'images': 328, 'long': 329, 'read': 330, 'subtitles': 331, 'gender-bending': 332, 'generally': 333, 'quite': 334, 'direction': 335, 'fluid': 336, 'no-nonsense': 337, 'authority': 338, 'harris': 339, 'phifer': 340, 'cam': 341, 'ron': 342, 'seal': 343, 'deal': 344, 'had': 345, 'just': 346, 'gone': 347, 'step': 348, 'further': 349, 'hawaiian': 350, 'shirt': 351, 'classic': 352, 'casts': 353, 'talented': 354, 'actors': 355, 'uses': 356, 'landscape': 357, 'create': 358, 'wickedly': 359, 'watch': 360, 'provide': 361, 'keenest': 362, 'pleasures': 363, 'unpretentious': 364, 'charming': 365, 'quirky': 366, 'well-written': 367, 'well-acted': 368, 'bring': 369, 'tissues': 370, 'brings': 371, 'proper': 372, 'conviction': 373, 'role': 374, '(': 375, 'jason': 376, 'bourne': 377, ')': 378, 'great': 379, 'charm': 380, 'generosity': 381, 'diplomacy': 382, 'there': 383, 'poignant': 384, 'artist': 385, '90-plus': 386, 'years': 387, 'taking': 388, 'effort': 389, 'share': 390, 'impressions': 391, 'loss': 392, 'art': 393, 'cinematic': 394, 'bon': 395, 'bons': 396, 'lively': 397, 'engaging': 398, 'examination': 399, 'similar': 400, 'obsessions': 401, 'dominate': 402, 'many': 403, 'challenges': 404, 'poses': 405, 'itself': 406, 'forgive': 407, 'serves': 408, 'workable': 409, 'primer': 410, 'region': 411, 'recent': 412, 'history': 413, 'make': 414, '10th-grade': 415, 'learning': 416, 'tool': 417, 'wide-awake': 418, 'effective': 419, 'stick': 420, 'underscore': 421, 'importance': 422, 'tradition': 423, 'familial': 424, 'community': 425, 'delivers': 426, 'promises': 427, ':': 428, 'look': 429, 'wild': 430, 'ride': 431, 'ensues': 432, 'brash': 433, 'set': 434, 'conquer': 435, 'online': 436, 'laptops': 437, 'cell': 438, 'phones': 439, 'sketchy': 440, 'business': 441, 'plans': 442, 'tasteful': 443, 'rock': 444, 'roll': 445, 'realistic': 446, 'portrayal': 447, 'well-thought': 448, 'stunts': 449, 'or': 450, 'reveals': 451, 'important': 452, 'our': 453, 'special': 454, 'talents': 455, 'put': 456, 'service': 457, 'others': 458, 'welcome': 459, 'relief': 460, 'promise': 461, 'digital': 462, 'filmmaking': 463, 'extraordinary': 464, 'faith': 465, 'seen': 466, 'willing': 467, 'champion': 468, 'fallibility': 469, 'heart': 470, 'adaptation': 471, 'caruso': 472, 'descends': 473, 'into': 474, 'sub-tarantino': 475, 'cuteness': 476, 'part': 477, 'makes': 478, 'sure': 479, 'salton': 480, 'sea': 481, 'works': 482, 'noir': 483, 'should': 484, 'keeping': 485, 'tight': 486, 'nasty': 487, 'audacious': 488, 'moments': 489, 'final': 490, 'scene': 491, 'suck': 492, 'despite': 493, 'their': 494, 'eats': 495, 'meddles': 496, 'argues': 497, 'laughs': 498, 'kibbitzes': 499, 'fights': 500, 'compelling': 501, 'infectiously': 502, 'picture': 503, 'runs': 504, 'mere': 505, '84': 506, 'minutes': 507, 'no': 508, 'glance': 509, 'remarkable': 510, 'procession': 511, 'sweeping': 512, 'pictures': 513, 'reinvigorated': 514, 'romance': 515, 'genre': 516, 'passable': 517, 'date': 518, 'imax': 519, 'short': 520, 'pleasant': 521, 'oozing': 522, 'pokes': 523, 'provokes': 524, 'expressionistic': 525, 'license': 526, 'color': 527, 'depth': 528, 'ingenious': 529, 'year': 530, 'unpredictable': 531, 'elvira': 532, 'fans': 533, 'could': 534, 'hardly': 535, 'ask': 536}\n",
            "537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def encode_sentence(sentence):\n",
        "    \"\"\"\n",
        "    Encodes inputs\n",
        "    Returns input_ids, segment_ids, and attention_mask.\n",
        "    \"\"\"\n",
        "    max_length = 50\n",
        "    input_ids = []\n",
        "    for item in sentence.split():\n",
        "      if item in vocab_to_int:\n",
        "        input_ids.append(vocab_to_int[item])\n",
        "      else:\n",
        "        input_ids.append(vocab_to_int['<unk>'])\n",
        "    segment_ids = [0]*len(input_ids)\n",
        "    attention_mask = [1] * len(input_ids) #inputs['attention_mask']\n",
        "    padding_length = max_length - len(input_ids)\n",
        "    input_ids += [vocab_to_int['<pad>']] * padding_length\n",
        "    segment_ids += [0] * padding_length\n",
        "    attention_mask += [0] * padding_length\n",
        "    for input_elem in (input_ids, segment_ids, attention_mask):\n",
        "        assert len(input_elem) == max_length\n",
        "    return (\n",
        "        torch.tensor(input_ids).long(),\n",
        "        torch.tensor(segment_ids).long(),\n",
        "        torch.tensor(attention_mask).long(),\n",
        "    )\n",
        "\n",
        "def encode_label(label):\n",
        "    \"\"\"Wraps label in tensor.\"\"\"\n",
        "\n",
        "    return torch.tensor(label).long()\n",
        "\n"
      ],
      "metadata": {
        "id": "GJ0RsEBgqidq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxnDYmRRB1iP"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset wrapper. Used for storing, retrieving, encoding, caching, and batching samples.\n",
        "    \"\"\"\n",
        "    def __init__(self, sentences, labels):\n",
        "      ## Process text data (tokenization, encoding) and save this information into self.samples\n",
        "      self.sentences = sentences\n",
        "      self.labels = labels\n",
        "      self.cache = {}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        res = self.cache.get(i, None)\n",
        "        if res is None:\n",
        "          sentence = self.sentences[i]\n",
        "          label = self.labels[i]\n",
        "          input_ids, segment_ids, attention_mask = encode_sentence(sentence)\n",
        "          label_id = encode_label(label)\n",
        "          res = ((input_ids, segment_ids, attention_mask, label_id))\n",
        "        self.cache[i] = res\n",
        "        return res\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# Define the LSTM model\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(len(vocab_to_int), input_size, padding_idx=vocab_to_int['<pad>'])\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        ##initialize hidden and cell state\n",
        "        h = torch.zeros((self.num_layers*2, x.size(0), self.hidden_size))\n",
        "        c = torch.zeros((self.num_layers*2, x.size(0), self.hidden_size))\n",
        "        h = nn.init.xavier_uniform_(h)\n",
        "        c = nn.init.xavier_uniform_(c)\n",
        "\n",
        "        # embedding\n",
        "        embedding = self.embedding(x)\n",
        "        # Forward pass through the LSTM\n",
        "        out, (h_n, c_n) = self.lstm(embedding, (h,c))  # out: output features, h_n: hidden state, c_n: cell state\n",
        "\n",
        "        # Apply dropout\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        # Take the output from the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "metadata": {
        "id": "p_9Ak6sl66f1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TextDataset(train_texts, train_labels)\n",
        "print(f'train samples = {len(train_dataset)}')\n",
        "dev_dataset = TextDataset(dev_texts, dev_labels)\n",
        "print(f'dev samples = {len(dev_dataset)}')\n",
        "test_dataset = TextDataset(test_texts, test_labels)\n",
        "print(f'test samples = {len(test_dataset)}')\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size, shuffle=True)\n",
        "\n",
        "\n",
        "# Example usage\n",
        "input_size = 128\n",
        "hidden_size = 64\n",
        "num_layers = 2\n",
        "output_size = 2\n",
        "\n",
        "# Create LSTM model\n",
        "model = LSTMModel(input_size, hidden_size, num_layers)\n",
        "print(model)\n",
        "\n",
        "from torch import nn\n",
        "from torch.optim import SGD, AdamW\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 0.으로 설정되어 있던 초기값 변경\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# Optimizer 설정 (AdamW 사용)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "\n",
        "##Train API should return (1) train loss and (2) train dataset accuracy, of the current epoch\n",
        "# Requirement: Initialize optimizer and do optimizer.step() once the current iteration is done\n",
        "#              The cross-entropy loss (criterion declared above) should be used to calculate the loss inside this train API\n",
        "def train(loader, epoch):\n",
        "  model.train()\n",
        "  train_loss = 0.\n",
        "  pred,true = [], []\n",
        "  ###############################################################################\n",
        "\n",
        "  for batch_idx, (input_ids, segment_ids, attention_mask, labels) in enumerate(loader):\n",
        "      # Optimizer 초기화\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Forward pass\n",
        "      outputs = model(input_ids)\n",
        "      loss = criterion(outputs, labels)\n",
        "\n",
        "      # Backward pass 및 Optimization\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)  # Gradient clipping\n",
        "      optimizer.step()\n",
        "\n",
        "      # 손실 계산 및 예측 결과 저장\n",
        "      train_loss += loss.item()\n",
        "      preds = outputs.argmax(dim=1)\n",
        "      pred.extend(preds.cpu().numpy())\n",
        "      true.extend(labels.cpu().numpy())\n",
        "\n",
        "  # 평균 손실 및 정확도 계산\n",
        "  train_loss /= len(loader)\n",
        "  train_acc = accuracy_score(true, pred)\n",
        "\n",
        "  ###############################################################################\n",
        "  return train_loss, train_acc\n",
        "## Test API\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    eval_loss = 0.\n",
        "    eval_acc = 0.\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    ###############################################################################\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_ids, segment_ids, attention_mask, labels in loader:\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # 손실 계산 및 예측 결과 저장\n",
        "            eval_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "            y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "    # 평균 손실 및 정확도 계산\n",
        "    eval_loss /= len(loader)\n",
        "    eval_acc = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    ###############################################################################\n",
        "\n",
        "    return eval_loss, eval_acc\n",
        "\n",
        "epochs = 100\n",
        "eval_loss = -float('inf')\n",
        "for epoch in range(1,epochs+1):\n",
        "  train_loss, train_acc = train(train_loader, epoch)\n",
        "  cur_eval_loss, cur_eval_acc = evaluate(dev_loader)\n",
        "  print(f'{epoch} epoch, train_loss = {train_loss},train_acc:{train_acc}, eval_loss:{cur_eval_loss}, eval_acc:{cur_eval_acc}')\n",
        "  if cur_eval_loss < eval_loss:\n",
        "    best_loss = cur_eval_loss\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5IIqkBd6-Z_",
        "outputId": "de26469f-3a6a-4a38-d1b5-9ee52bbd8f8f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train samples = 100\n",
            "dev samples = 100\n",
            "test samples = 100\n",
            "LSTMModel(\n",
            "  (embedding): Embedding(537, 128, padding_idx=0)\n",
            "  (lstm): LSTM(128, 64, num_layers=2, batch_first=True, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
            ")\n",
            "1 epoch, train_loss = 0.7125120759010315,train_acc:0.08, eval_loss:0.6821868717670441, eval_acc:1.0\n",
            "2 epoch, train_loss = 0.6733531653881073,train_acc:0.83, eval_loss:0.6449496746063232, eval_acc:1.0\n",
            "3 epoch, train_loss = 0.6361564993858337,train_acc:1.0, eval_loss:0.6052186489105225, eval_acc:1.0\n",
            "4 epoch, train_loss = 0.5937031507492065,train_acc:1.0, eval_loss:0.5608544647693634, eval_acc:1.0\n",
            "5 epoch, train_loss = 0.5506621897220612,train_acc:1.0, eval_loss:0.5079826414585114, eval_acc:1.0\n",
            "6 epoch, train_loss = 0.4945513755083084,train_acc:1.0, eval_loss:0.44092491269111633, eval_acc:1.0\n",
            "7 epoch, train_loss = 0.42556042969226837,train_acc:1.0, eval_loss:0.3536214679479599, eval_acc:1.0\n",
            "8 epoch, train_loss = 0.3285590410232544,train_acc:1.0, eval_loss:0.247004434466362, eval_acc:1.0\n",
            "9 epoch, train_loss = 0.221144400537014,train_acc:1.0, eval_loss:0.14317745715379715, eval_acc:1.0\n",
            "10 epoch, train_loss = 0.12460611388087273,train_acc:1.0, eval_loss:0.07007177546620369, eval_acc:1.0\n",
            "11 epoch, train_loss = 0.06204012781381607,train_acc:1.0, eval_loss:0.029393560253083706, eval_acc:1.0\n",
            "12 epoch, train_loss = 0.02515434008091688,train_acc:1.0, eval_loss:0.01227165199816227, eval_acc:1.0\n",
            "13 epoch, train_loss = 0.01361683290451765,train_acc:1.0, eval_loss:0.005782309453934431, eval_acc:1.0\n",
            "14 epoch, train_loss = 0.006008794065564871,train_acc:1.0, eval_loss:0.0031116692116484046, eval_acc:1.0\n",
            "15 epoch, train_loss = 0.0031482509803026915,train_acc:1.0, eval_loss:0.0018622290226630867, eval_acc:1.0\n",
            "16 epoch, train_loss = 0.002502172254025936,train_acc:1.0, eval_loss:0.0012116148718632758, eval_acc:1.0\n",
            "17 epoch, train_loss = 0.0013681495911441743,train_acc:1.0, eval_loss:0.0008436921634711325, eval_acc:1.0\n",
            "18 epoch, train_loss = 0.0010744596365839243,train_acc:1.0, eval_loss:0.0006234686297830194, eval_acc:1.0\n",
            "19 epoch, train_loss = 0.00078287796350196,train_acc:1.0, eval_loss:0.0004835950385313481, eval_acc:1.0\n",
            "20 epoch, train_loss = 0.0005909794708713889,train_acc:1.0, eval_loss:0.00039214349817484617, eval_acc:1.0\n",
            "21 epoch, train_loss = 0.0005358397611416876,train_acc:1.0, eval_loss:0.000328214475302957, eval_acc:1.0\n",
            "22 epoch, train_loss = 0.0005345412791939452,train_acc:1.0, eval_loss:0.0002826310519594699, eval_acc:1.0\n",
            "23 epoch, train_loss = 0.00032475618354510516,train_acc:1.0, eval_loss:0.00024946419580373913, eval_acc:1.0\n",
            "24 epoch, train_loss = 0.00033870832703541964,train_acc:1.0, eval_loss:0.00022411483223550022, eval_acc:1.0\n",
            "25 epoch, train_loss = 0.00031970014970283955,train_acc:1.0, eval_loss:0.00020500043319771066, eval_acc:1.0\n",
            "26 epoch, train_loss = 0.00031144988315645605,train_acc:1.0, eval_loss:0.00018947236094390973, eval_acc:1.0\n",
            "27 epoch, train_loss = 0.0003121026820736006,train_acc:1.0, eval_loss:0.00017766471864888445, eval_acc:1.0\n",
            "28 epoch, train_loss = 0.000276422273600474,train_acc:1.0, eval_loss:0.00016764429165050387, eval_acc:1.0\n",
            "29 epoch, train_loss = 0.00024139101151376963,train_acc:1.0, eval_loss:0.00015958294534357265, eval_acc:1.0\n",
            "30 epoch, train_loss = 0.0002414431146462448,train_acc:1.0, eval_loss:0.00015305094711948186, eval_acc:1.0\n",
            "31 epoch, train_loss = 0.00030405231518670917,train_acc:1.0, eval_loss:0.00014714238204760477, eval_acc:1.0\n",
            "32 epoch, train_loss = 0.00026114279171451926,train_acc:1.0, eval_loss:0.00014217417628969997, eval_acc:1.0\n",
            "33 epoch, train_loss = 0.00022722978610545397,train_acc:1.0, eval_loss:0.0001378862580168061, eval_acc:1.0\n",
            "34 epoch, train_loss = 0.00016909597616177052,train_acc:1.0, eval_loss:0.00013398309965850785, eval_acc:1.0\n",
            "35 epoch, train_loss = 0.00018694875325309113,train_acc:1.0, eval_loss:0.00013054811279289424, eval_acc:1.0\n",
            "36 epoch, train_loss = 0.0001700834254734218,train_acc:1.0, eval_loss:0.00012769810564350337, eval_acc:1.0\n",
            "37 epoch, train_loss = 0.0001981597306439653,train_acc:1.0, eval_loss:0.00012511785462265834, eval_acc:1.0\n",
            "38 epoch, train_loss = 0.00019250116019975394,train_acc:1.0, eval_loss:0.00012275619519641623, eval_acc:1.0\n",
            "39 epoch, train_loss = 0.00020721273904200643,train_acc:1.0, eval_loss:0.00012060407971148379, eval_acc:1.0\n",
            "40 epoch, train_loss = 0.00023584282462252304,train_acc:1.0, eval_loss:0.00011845690096379258, eval_acc:1.0\n",
            "41 epoch, train_loss = 0.00017411438602721319,train_acc:1.0, eval_loss:0.00011646390339592472, eval_acc:1.0\n",
            "42 epoch, train_loss = 0.0001547708743601106,train_acc:1.0, eval_loss:0.00011468466254882514, eval_acc:1.0\n",
            "43 epoch, train_loss = 0.00019166072888765484,train_acc:1.0, eval_loss:0.00011289703252259642, eval_acc:1.0\n",
            "44 epoch, train_loss = 0.00017167269834317267,train_acc:1.0, eval_loss:0.0001112984464270994, eval_acc:1.0\n",
            "45 epoch, train_loss = 0.000160581614181865,train_acc:1.0, eval_loss:0.0001097070962714497, eval_acc:1.0\n",
            "46 epoch, train_loss = 0.00017638446297496557,train_acc:1.0, eval_loss:0.00010829970415215939, eval_acc:1.0\n",
            "47 epoch, train_loss = 0.0001690919598331675,train_acc:1.0, eval_loss:0.00010691374336602166, eval_acc:1.0\n",
            "48 epoch, train_loss = 0.00014622119488194585,train_acc:1.0, eval_loss:0.0001053998785209842, eval_acc:1.0\n",
            "49 epoch, train_loss = 0.00015343000268330798,train_acc:1.0, eval_loss:0.00010403097985545173, eval_acc:1.0\n",
            "50 epoch, train_loss = 0.00015103564510354772,train_acc:1.0, eval_loss:0.0001026469653879758, eval_acc:1.0\n",
            "51 epoch, train_loss = 0.00016309001512126997,train_acc:1.0, eval_loss:0.00010155267227673903, eval_acc:1.0\n",
            "52 epoch, train_loss = 0.00020972481434000656,train_acc:1.0, eval_loss:0.00010019514593295753, eval_acc:1.0\n",
            "53 epoch, train_loss = 0.00015158133464865386,train_acc:1.0, eval_loss:9.905314436764456e-05, eval_acc:1.0\n",
            "54 epoch, train_loss = 0.00017868315626401454,train_acc:1.0, eval_loss:9.779723040992394e-05, eval_acc:1.0\n",
            "55 epoch, train_loss = 0.00011982353316852823,train_acc:1.0, eval_loss:9.657565897214226e-05, eval_acc:1.0\n",
            "56 epoch, train_loss = 0.00015755843924125656,train_acc:1.0, eval_loss:9.55127070483286e-05, eval_acc:1.0\n",
            "57 epoch, train_loss = 0.00018652308790478855,train_acc:1.0, eval_loss:9.431555736227892e-05, eval_acc:1.0\n",
            "58 epoch, train_loss = 0.00017528530588606372,train_acc:1.0, eval_loss:9.322715050075203e-05, eval_acc:1.0\n",
            "59 epoch, train_loss = 0.00011300175174255855,train_acc:1.0, eval_loss:9.21179489523638e-05, eval_acc:1.0\n",
            "60 epoch, train_loss = 0.0001253619630006142,train_acc:1.0, eval_loss:9.096662688534707e-05, eval_acc:1.0\n",
            "61 epoch, train_loss = 0.00013107191625749692,train_acc:1.0, eval_loss:8.992695074994117e-05, eval_acc:1.0\n",
            "62 epoch, train_loss = 0.00015297111531253904,train_acc:1.0, eval_loss:8.906141738407314e-05, eval_acc:1.0\n",
            "63 epoch, train_loss = 0.00016093370504677296,train_acc:1.0, eval_loss:8.805919424048625e-05, eval_acc:1.0\n",
            "64 epoch, train_loss = 0.00013928506086813286,train_acc:1.0, eval_loss:8.688478919793852e-05, eval_acc:1.0\n",
            "65 epoch, train_loss = 0.00014241789540392347,train_acc:1.0, eval_loss:8.59230240166653e-05, eval_acc:1.0\n",
            "66 epoch, train_loss = 0.00011829800132545643,train_acc:1.0, eval_loss:8.511977284797467e-05, eval_acc:1.0\n",
            "67 epoch, train_loss = 0.00014857101268717088,train_acc:1.0, eval_loss:8.417953722528182e-05, eval_acc:1.0\n",
            "68 epoch, train_loss = 0.00017169551574625075,train_acc:1.0, eval_loss:8.31705765449442e-05, eval_acc:1.0\n",
            "69 epoch, train_loss = 0.00014241173266782425,train_acc:1.0, eval_loss:8.225599958677776e-05, eval_acc:1.0\n",
            "70 epoch, train_loss = 0.00013233980280347168,train_acc:1.0, eval_loss:8.132505899993703e-05, eval_acc:1.0\n",
            "71 epoch, train_loss = 0.00013884650252293795,train_acc:1.0, eval_loss:8.042928675422445e-05, eval_acc:1.0\n",
            "72 epoch, train_loss = 0.00012229234198457561,train_acc:1.0, eval_loss:7.945748802740127e-05, eval_acc:1.0\n",
            "73 epoch, train_loss = 0.00015215307212201878,train_acc:1.0, eval_loss:7.864430517656729e-05, eval_acc:1.0\n",
            "74 epoch, train_loss = 0.00013583377585746348,train_acc:1.0, eval_loss:7.782273314660415e-05, eval_acc:1.0\n",
            "75 epoch, train_loss = 0.00012664670794038102,train_acc:1.0, eval_loss:7.690182974329218e-05, eval_acc:1.0\n",
            "76 epoch, train_loss = 0.0001414734433637932,train_acc:1.0, eval_loss:7.604228449054062e-05, eval_acc:1.0\n",
            "77 epoch, train_loss = 0.00013113711611367762,train_acc:1.0, eval_loss:7.514776734751649e-05, eval_acc:1.0\n",
            "78 epoch, train_loss = 9.892290472635068e-05,train_acc:1.0, eval_loss:7.442666537826881e-05, eval_acc:1.0\n",
            "79 epoch, train_loss = 0.00014385256508830935,train_acc:1.0, eval_loss:7.355987327173352e-05, eval_acc:1.0\n",
            "80 epoch, train_loss = 0.00012530304229585454,train_acc:1.0, eval_loss:7.279282726813108e-05, eval_acc:1.0\n",
            "81 epoch, train_loss = 0.00010993205796694383,train_acc:1.0, eval_loss:7.217757956823334e-05, eval_acc:1.0\n",
            "82 epoch, train_loss = 0.00011102738790214062,train_acc:1.0, eval_loss:7.14291600161232e-05, eval_acc:1.0\n",
            "83 epoch, train_loss = 0.00011536999954842031,train_acc:1.0, eval_loss:7.063997691147961e-05, eval_acc:1.0\n",
            "84 epoch, train_loss = 9.920302909449674e-05,train_acc:1.0, eval_loss:6.991628833930008e-05, eval_acc:1.0\n",
            "85 epoch, train_loss = 0.00011840332808787934,train_acc:1.0, eval_loss:6.92024223098997e-05, eval_acc:1.0\n",
            "86 epoch, train_loss = 0.00011704094504239038,train_acc:1.0, eval_loss:6.859379573143087e-05, eval_acc:1.0\n",
            "87 epoch, train_loss = 0.0001216309356095735,train_acc:1.0, eval_loss:6.792359636165202e-05, eval_acc:1.0\n",
            "88 epoch, train_loss = 0.00012110011448385194,train_acc:1.0, eval_loss:6.719576776959002e-05, eval_acc:1.0\n",
            "89 epoch, train_loss = 9.151132326223888e-05,train_acc:1.0, eval_loss:6.658713755314238e-05, eval_acc:1.0\n",
            "90 epoch, train_loss = 0.00012474389586714096,train_acc:1.0, eval_loss:6.601534914807416e-05, eval_acc:1.0\n",
            "91 epoch, train_loss = 8.932351920520887e-05,train_acc:1.0, eval_loss:6.526143988594413e-05, eval_acc:1.0\n",
            "92 epoch, train_loss = 0.00010409861715743318,train_acc:1.0, eval_loss:6.467183993663639e-05, eval_acc:1.0\n",
            "93 epoch, train_loss = 0.00013764758477918804,train_acc:1.0, eval_loss:6.40051621303428e-05, eval_acc:1.0\n",
            "94 epoch, train_loss = 9.458030763198622e-05,train_acc:1.0, eval_loss:6.340967593132518e-05, eval_acc:1.0\n",
            "95 epoch, train_loss = 0.00010223172284895554,train_acc:1.0, eval_loss:6.279442095546983e-05, eval_acc:1.0\n",
            "96 epoch, train_loss = 0.00011769356569857337,train_acc:1.0, eval_loss:6.224166281754151e-05, eval_acc:1.0\n",
            "97 epoch, train_loss = 0.00011173522216267884,train_acc:1.0, eval_loss:6.1483406170737e-05, eval_acc:1.0\n",
            "98 epoch, train_loss = 0.00010779496005852707,train_acc:1.0, eval_loss:6.105212742113508e-05, eval_acc:1.0\n",
            "99 epoch, train_loss = 0.00012088875519111753,train_acc:1.0, eval_loss:6.042124186933506e-05, eval_acc:1.0\n",
            "100 epoch, train_loss = 9.3348920927383e-05,train_acc:1.0, eval_loss:5.982502625556663e-05, eval_acc:1.0\n"
          ]
        }
      ]
    }
  ]
}